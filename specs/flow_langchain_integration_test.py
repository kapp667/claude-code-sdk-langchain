"""
Test de flux : IntÃ©gration avec chaÃ®nes LangChain
"""

import asyncio
import pytest
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import HumanMessage


def test_simple_chain():
    """Test d'une chaÃ®ne simple avec prompt et modÃ¨le"""
    from src.claude_code_langchain import ClaudeCodeChatModel

    # CrÃ©er les composants
    model = ClaudeCodeChatModel(
        model="claude-sonnet-4-20250514",
        temperature=0.5,
        max_tokens=200
    )

    prompt = ChatPromptTemplate.from_messages([
        ("system", "Tu es un assistant qui rÃ©pond en {language}"),
        ("human", "{question}")
    ])

    # CrÃ©er la chaÃ®ne
    chain = prompt | model

    try:
        # Invoquer la chaÃ®ne
        response = chain.invoke({
            "language": "franÃ§ais",
            "question": "Qu'est-ce que Python?"
        })

        # Valider
        assert response is not None
        assert len(response.content) > 0

        print(f"âœ… Test chaÃ®ne simple rÃ©ussi")
        print(f"   RÃ©ponse: {response.content[:100]}...")

    except Exception as e:
        pytest.fail(f"Ã‰chec test chaÃ®ne simple: {e}")


def test_chain_with_parser():
    """Test d'une chaÃ®ne avec output parser"""
    from src.claude_code_langchain import ClaudeCodeChatModel

    # CrÃ©er les composants
    model = ClaudeCodeChatModel(
        model="claude-sonnet-4-20250514",
        temperature=0.3,
        max_tokens=150
    )

    prompt = ChatPromptTemplate.from_messages([
        ("system", "RÃ©ponds toujours de maniÃ¨re trÃ¨s concise"),
        ("human", "{input}")
    ])

    parser = StrOutputParser()

    # CrÃ©er la chaÃ®ne complÃ¨te
    chain = prompt | model | parser

    try:
        # Invoquer la chaÃ®ne
        response = chain.invoke({
            "input": "DÃ©finis Python en 5 mots maximum"
        })

        # Valider que c'est bien une string parsÃ©e
        assert isinstance(response, str)
        assert len(response) > 0

        print(f"âœ… Test chaÃ®ne avec parser rÃ©ussi")
        print(f"   RÃ©ponse parsÃ©e: {response}")

    except Exception as e:
        pytest.fail(f"Ã‰chec test avec parser: {e}")


@pytest.mark.asyncio
async def test_async_chain():
    """Test d'une chaÃ®ne asynchrone"""
    from src.claude_code_langchain import ClaudeCodeChatModel

    # CrÃ©er les composants
    model = ClaudeCodeChatModel(
        model="claude-sonnet-4-20250514",
        temperature=0.7
    )

    prompt = ChatPromptTemplate.from_messages([
        ("system", "Tu es un expert en {domain}"),
        ("human", "Explique {concept}")
    ])

    chain = prompt | model | StrOutputParser()

    try:
        # Invoquer de maniÃ¨re asynchrone
        response = await chain.ainvoke({
            "domain": "informatique",
            "concept": "les algorithmes"
        })

        # Valider
        assert isinstance(response, str)
        assert len(response) > 0

        print(f"âœ… Test chaÃ®ne async rÃ©ussi")
        print(f"   RÃ©ponse: {response[:100]}...")

    except Exception as e:
        pytest.fail(f"Ã‰chec test async: {e}")


def test_batch_processing():
    """Test du traitement par batch"""
    from src.claude_code_langchain import ClaudeCodeChatModel

    # CrÃ©er le modÃ¨le
    model = ClaudeCodeChatModel(
        model="claude-sonnet-4-20250514",
        temperature=0.5,
        max_tokens=100
    )

    # CrÃ©er plusieurs messages
    batch_inputs = [
        [HumanMessage(content="Qu'est-ce que 2+2?")],
        [HumanMessage(content="Capitale de la France?")],
        [HumanMessage(content="Couleur du ciel?")]
    ]

    try:
        # Traiter en batch
        responses = model.batch(batch_inputs)

        # Valider
        assert len(responses) == 3
        for response in responses:
            assert response is not None
            assert len(response.content) > 0

        print(f"âœ… Test batch rÃ©ussi")
        print(f"   {len(responses)} rÃ©ponses reÃ§ues")

    except Exception as e:
        pytest.fail(f"Ã‰chec test batch: {e}")


def test_streaming_chain():
    """Test du streaming dans une chaÃ®ne"""
    from src.claude_code_langchain import ClaudeCodeChatModel

    # CrÃ©er les composants
    model = ClaudeCodeChatModel(
        model="claude-sonnet-4-20250514",
        temperature=0.7
    )

    prompt = ChatPromptTemplate.from_messages([
        ("human", "Raconte une courte histoire sur {topic}")
    ])

    chain = prompt | model

    try:
        # Stream la rÃ©ponse
        chunks_count = 0
        for chunk in chain.stream({"topic": "un robot"}):
            chunks_count += 1
            print(".", end="", flush=True)

        print()  # Nouvelle ligne
        assert chunks_count > 0

        print(f"âœ… Test streaming chaÃ®ne rÃ©ussi")
        print(f"   {chunks_count} chunks streamÃ©s")

    except Exception as e:
        pytest.fail(f"Ã‰chec test streaming: {e}")


def test_complex_chain_with_multiple_steps():
    """Test d'une chaÃ®ne complexe avec plusieurs Ã©tapes"""
    from src.claude_code_langchain import ClaudeCodeChatModel
    from langchain_core.runnables import RunnablePassthrough

    # CrÃ©er le modÃ¨le
    model = ClaudeCodeChatModel(
        model="claude-sonnet-4-20250514",
        temperature=0.5,
        max_tokens=150
    )

    # PremiÃ¨re Ã©tape : classifier
    classify_prompt = ChatPromptTemplate.from_messages([
        ("system", "Classifie le texte suivant en 'positif', 'nÃ©gatif' ou 'neutre'"),
        ("human", "{text}")
    ])

    # DeuxiÃ¨me Ã©tape : rÃ©pondre selon la classification
    response_prompt = ChatPromptTemplate.from_messages([
        ("system", "Le sentiment est {sentiment}. RÃ©ponds de maniÃ¨re appropriÃ©e."),
        ("human", "Comment rÃ©agir Ã : {text}")
    ])

    # ChaÃ®ne complexe
    classify_chain = classify_prompt | model | StrOutputParser()

    def create_response_input(inputs):
        sentiment = classify_chain.invoke({"text": inputs["text"]})
        return {
            "sentiment": sentiment,
            "text": inputs["text"]
        }

    complex_chain = RunnablePassthrough.assign(
        sentiment=lambda x: classify_chain.invoke({"text": x["text"]})
    ) | response_prompt | model | StrOutputParser()

    try:
        # Test avec un texte
        response = complex_chain.invoke({
            "text": "Ce produit est absolument fantastique!"
        })

        # Valider
        assert isinstance(response, str)
        assert len(response) > 0

        print(f"âœ… Test chaÃ®ne complexe rÃ©ussi")
        print(f"   RÃ©ponse: {response[:150]}...")

    except Exception as e:
        pytest.fail(f"Ã‰chec test chaÃ®ne complexe: {e}")


if __name__ == "__main__":
    # ExÃ©cuter les tests
    print("ğŸ§ª Tests d'intÃ©gration LangChain\n")

    print("1. Test chaÃ®ne simple...")
    test_simple_chain()

    print("\n2. Test avec parser...")
    test_chain_with_parser()

    print("\n3. Test async...")
    asyncio.run(test_async_chain())

    print("\n4. Test batch...")
    test_batch_processing()

    print("\n5. Test streaming chaÃ®ne...")
    test_streaming_chain()

    print("\n6. Test chaÃ®ne complexe...")
    test_complex_chain_with_multiple_steps()

    print("\nâœ… Tous les tests d'intÃ©gration passÃ©s!")