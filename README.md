# Claude Code SDK - LangChain Adapter

Utilisez Claude via votre abonnement Claude Code (20$/mois) comme mod√®le LLM dans LangChain pour prototyper des applications agentiques **SANS frais API suppl√©mentaires** !

## üéØ Objectif

Cet adaptateur permet d'utiliser votre abonnement Claude Code existant comme backend pour LangChain, vous permettant de :
- ‚úÖ Prototyper des applications LangChain gratuitement (via votre abonnement)
- ‚úÖ Tester des id√©es d'agents sans se soucier des co√ªts API
- ‚úÖ Migrer facilement vers l'API officielle en production

## üì¶ Installation

```bash
# 1. Installer les d√©pendances
pip install claude-code-sdk langchain langchain-core

# 2. S'assurer que Claude Code CLI est install√©
npm install -g @anthropic-ai/claude-code
```

## üöÄ Utilisation Rapide

```python
from src.claude_code_langchain import ClaudeCodeChatModel
from langchain_core.prompts import ChatPromptTemplate

# Cr√©er le mod√®le (utilise votre abonnement Claude Code)
model = ClaudeCodeChatModel(
    model="claude-sonnet-4-20250514",
    temperature=0.7
)

# Utilisation simple
response = model.invoke("Qu'est-ce que LangChain?")
print(response.content)

# Dans une cha√Æne LangChain
prompt = ChatPromptTemplate.from_messages([
    ("system", "Tu es un assistant expert en {domain}"),
    ("human", "{question}")
])

chain = prompt | model
result = chain.invoke({
    "domain": "Python",
    "question": "Comment cr√©er une API REST?"
})
```

## üîÑ Streaming

```python
# Streaming de r√©ponses
for chunk in model.stream("Raconte une histoire"):
    print(chunk.content, end="")

# Streaming asynchrone
async for chunk in model.astream("Liste 5 id√©es"):
    print(chunk.content, end="")
```

## üîó Int√©gration LangChain Compl√®te

L'adaptateur supporte toutes les fonctionnalit√©s LangChain :
- ‚úÖ Invocation synchrone/asynchrone
- ‚úÖ Streaming
- ‚úÖ Batch processing
- ‚úÖ Int√©gration LCEL (LangChain Expression Language)
- ‚úÖ Cha√Ænes et agents

## üìù Exemples

Voir le dossier `examples/` pour des exemples complets :
- `basic_usage.py` - Exemples d'utilisation vari√©s
- Tests dans `specs/` - Tests de flux pragmatiques

## üß™ Tests

```bash
# Ex√©cuter les tests de flux
python specs/flow_basic_chat_test.py
python specs/flow_langchain_integration_test.py

# Ou avec pytest
pytest specs/
```

## üîÑ Migration vers Production

Quand vous √™tes pr√™t pour la production, remplacez simplement :

```python
# D√©veloppement (votre abonnement)
from src.claude_code_langchain import ClaudeCodeChatModel
model = ClaudeCodeChatModel(model="claude-sonnet-4-20250514")

# Production (API officielle)
from langchain_anthropic import ChatAnthropic
model = ChatAnthropic(model="claude-3-opus-20240229", api_key="sk-...")
```

Le reste de votre code reste identique !

## ‚öôÔ∏è Configuration

```python
model = ClaudeCodeChatModel(
    model="claude-sonnet-4-20250514",     # Mod√®le Claude Sonnet 4
    temperature=0.7,                      # ‚ö†Ô∏è NON SUPPORT√â (valeur ignor√©e)
    max_tokens=2000,                      # ‚ö†Ô∏è NON SUPPORT√â (valeur ignor√©e)
    system_prompt="Tu es un expert...",  # Prompt syst√®me
    permission_mode="default",            # Mode permissions Claude Code
)
```

## üèóÔ∏è Architecture

```
LangChain App
     ‚Üì
ClaudeCodeChatModel (cet adaptateur)
     ‚Üì
claude-code-sdk (SDK Python)
     ‚Üì
Claude Code CLI
     ‚Üì
Claude (via votre abonnement)
```

## ‚ö†Ô∏è Limitations et Avertissements

Cette section documente les limitations connues de l'adaptateur. Ces limitations sont **intentionnelles** - elles repr√©sentent les trade-offs entre prototypage cost-free et API de production. L'adaptateur √©met des **warnings runtime** pour vous pr√©venir quand vous utilisez des fonctionnalit√©s non support√©es.

### üå°Ô∏è Temperature et Max_Tokens

**Limitation** : Le Claude Code CLI ne supporte pas les param√®tres `temperature` et `max_tokens`.

**Comportement** :
- Ces param√®tres sont **accept√©s pour compatibilit√© API** (√©vite de casser votre code)
- Ils **n'ont aucun effet** sur la g√©n√©ration
- Un **warning est √©mis** au moment de l'initialisation si vous sp√©cifiez des valeurs non-d√©faut

**Pour le D√©veloppement (Claude Code):**
```python
model = ClaudeCodeChatModel()  # Utilise les valeurs par d√©faut du mod√®le
# ‚ö†Ô∏è temperature=0.7 et max_tokens=2000 n'auront aucun effet
```

**Pour la Production (avec contr√¥le des param√®tres):**
```python
from langchain_anthropic import ChatAnthropic
model = ChatAnthropic(
    temperature=0.7,      # ‚úÖ Fonctionne en production
    max_tokens=1000,      # ‚úÖ Fonctionne en production
    api_key=os.getenv("ANTHROPIC_API_KEY")
)
```

**Pourquoi ?** Le CLI Claude Code ne expose pas de flags `--temperature` ou `--max-tokens`. Investigation compl√®te : [`docs/TEMPERATURE_MAX_TOKENS_INVESTIGATION.md`](docs/TEMPERATURE_MAX_TOKENS_INVESTIGATION.md)

**Solution** : Si vous avez besoin du contr√¥le de temp√©rature ou de limite de tokens pendant le d√©veloppement, utilisez directement l'API de production avec votre cl√© API Anthropic.

---

### üñºÔ∏è Vision et Contenu Multimodal

**Limitation** : Les images et autres contenus non-texte ne sont pas support√©s.

**Comportement** :
- Le texte est extrait et trait√©
- Les images sont **silencieusement ignor√©es**
- Un **warning est √©mis** quand une image est d√©tect√©e dans les messages

**Exemple** :
```python
messages = [
    HumanMessage(content=[
        {"type": "text", "text": "D√©cris cette image"},
        {"type": "image_url", "image_url": {"url": "https://..."}}  # ‚ö†Ô∏è Ignor√©
    ])
]
# Warning: Image content detected but NOT SUPPORTED by Claude Code SDK
```

**Pourquoi ?** Le SDK Claude Code ne g√®re pas les messages multimodaux via le CLI.

**Solution** : Pour les t√¢ches vision, utilisez `ChatAnthropic` avec l'API de production qui supporte vision nativement.

---

### üîÑ Support Async

**Support Complet** ‚úÖ : L'adaptateur supporte maintenant compl√®tement les op√©rations asynchrones gr√¢ce √† un fix d'isolation anyio.

**‚úÖ Op√©rations Sync (100%)**
- `model.invoke()` - Support complet
- `model.stream()` - Support complet
- `model.batch()` - Support complet
- Cha√Ænes avec ex√©cution sync - Support complet

**‚úÖ Op√©rations Async (100%)**
- `model.ainvoke()` - Support complet
- `model.astream()` - Streaming complet avec isolation anyio
- `chain.astream()` avec parsers - **Support complet** (fix anyio/asyncio via queue)
- Cancellation de stream - Support√© via break ou cancel()

**Tests** : 16/16 tests fonctionnels passent (100%) ‚úÖ

**Note technique** : Un probl√®me `RuntimeError: cancel scope in different task` avec LangChain parsers a √©t√© r√©solu via un pattern de queue isolation. D√©tails : [`CLAUDE.md`](CLAUDE.md#critical-implementation-details)

---

### üîß System Prompt - Conflit de Sources

**Limitation** : Si vous sp√©cifiez un `system_prompt` dans le constructor ET un `SystemMessage` dans les messages, il y a pr√©c√©dence.

**Comportement** :
- `SystemMessage` dans les messages **prend pr√©c√©dence**
- Constructor `system_prompt` est **ignor√©**
- Un **warning est √©mis** si les deux sont pr√©sents

**Pourquoi ?** Pour √©viter d'avoir deux system prompts contradictoires et assurer un comportement pr√©visible.

---

### ‚ö° Autres Limitations

| Limitation | Impact | Solution |
|------------|--------|----------|
| **Tool calls** | Pas de support natif | Peut √™tre simul√© via prompting explicite |
| **Latence** | +10-30% vs API directe | Trade-off acceptable pour prototypage |
| **CLI Required** | N√©cessite `npm install -g @anthropic-ai/claude-code` | Installation une fois |
| **Quotas** | Limit√©s par votre abonnement Claude Code | Passer √† API production si d√©pass√© |

---

### üìä Neutralit√© Comportementale

**Score global** : ~95%

L'adaptateur maintient une **haute neutralit√© comportementale** avec l'API de production :
- ‚úÖ Messages et formats : 100% compatible
- ‚úÖ Streaming et async : 100% compatible
- ‚ö†Ô∏è Param√®tres sampling : Non support√© (temperature, max_tokens)
- ‚ö†Ô∏è Vision : Non support√©
- ‚úÖ Comportement core : Identique √† ChatAnthropic

**Validation** : 3 agents sp√©cialis√©s ont analys√© l'impl√©mentation. Rapport complet : [`docs/VALIDATION_REPORT_2025-09-30.md`](docs/VALIDATION_REPORT_2025-09-30.md)

---

### üí° Recommandations

**Pour le Prototypage** (cet adaptateur) :
- ‚úÖ Notebooks Jupyter
- ‚úÖ Scripts CLI de test
- ‚úÖ Cha√Ænes LangChain basiques et complexes
- ‚úÖ Agents simples
- ‚úÖ Exp√©rimentation rapide

**Pour la Production** (ChatAnthropic) :
- ‚úÖ Applications n√©cessitant temperature control
- ‚úÖ T√¢ches vision/multimodal
- ‚úÖ D√©ploiements √† grande √©chelle
- ‚úÖ Contr√¥le pr√©cis de la g√©n√©ration
- ‚úÖ Tool calls natifs

**Migration** : Changer une ligne de code suffit (voir section Migration Path ci-dessus).

## ü§ù Contribution

Les contributions sont bienvenues ! N'h√©sitez pas √† :
- Ajouter des fonctionnalit√©s
- Am√©liorer la documentation
- Rapporter des bugs
- Proposer des optimisations

## üìÑ Licence

MIT

## üôè Remerciements

- Anthropic pour Claude et Claude Code
- LangChain pour le framework
- St√©phane Wootha Richard pour l'orchestration

---

**Note** : Cet adaptateur est parfait pour le prototypage et le d√©veloppement. Pour la production √† grande √©chelle, consid√©rez l'API officielle Anthropic.